{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wfmd8-y_TogG"
      },
      "source": [
        "## Accessing Ontologies using Natural Language\n",
        "Author: Akshay Govind S, IITM\n",
        "\n",
        "In this notebook, we explore ways to access Ontologies(RDF graph) using natural language queries by converting them to SPARQL queries and querying the RDF graph/![1_i6HgdoZ1pLnuK8fc639myw.webp](data:image/webp;base64,UklGRjxDAABXRUJQVlA4WAoAAAAIAAAAOwMAYQQAVlA4IJhCAADQqgGdASo8A2IEPm02l0kkIyUiIVM5AKANiWlu/BFZp0YK3H1Xx/53+J8A+P/Zv7v++fux46O1v1/qT4IPaGYH1g8pvzP/4nqj/WX/W9wX9cP1t9cH1lfux6jv5n/d/2q95H/eesb/M+oB/bP9R60v/K9jb+w/8n2Dv2h///rs/uz8Lv94/6H7k/Ar+1P/79gD0AOqH83/u3+M7ZP8P+Vnob+MfMf1j+0/sn/evcDyR8XfoV/Hftt+Q/v37l/GT+j/4fgr8ef6H7k/kC/G/5N/if7dvyuw/6/9lPYC9RPnX+k/tf+V/73+q+Dn3X/Cf3L9uP3/+R/rz/m/yp/uv///AD+W/0v/K/4D93/8X/////8YXg7fe/9v7AP8o/p3+T/t/+U/+H+J+m7+o/8H+g/2f7n+279A/xP/c/zf+v/bf7CP5T/T/+B/fv9J+1Xzuf//3IfuZ///dP/bT/+BzvDL5BU5tdvRzcMvkFTm129HNwy+QVObXb0c3DL5BU5tdvRzcMvkFTm129HNwy+QVObXb0c3DL5BU5tdvRxMOUJSSGBpXiuRjBRYkp8gqc2u3o5uGXyCpza7ejm4ZfIKI04H2DkvcwUWk+MtoQ3DL5BU5tdvRzcMvkFTm129HNwy9zRUiXDl7wy+QVObXb0c3DL5BU5tdvRzcMcxNRHJP7bm03OBRb+S2pHR5ocWM6THneGXyCpza7ejm4ZfIKnNrt6ObhHcXO7b/6Obhl8gqc2u3o5uGXyCpza7ejmiOx66Idm9L3y6XzU0a4g8rF+8MvkFTm129HNwy+QVObXb0c3DL3AxnHP2ImrJkp4z3tXSza7ejm4ZfIKnNrt6Obhl8gqc2u3o4u4bLt6Obhl8gqc2u3o5uGXyCpza7ejm4Y5T0tMHO8MvkFTm129HNwy+QVObXb0c3DLho+nDTBzvDL5BU5tdvRzcMvkFTm129HNECCa9l3FAsaRNsZwaoRcG2nRZLXFpyGmDneGXyCpza7ejm4ZfIKE3m4gyR6vyWBkTe7c119wdNQbH84vo5uGXyCpza7ejm4ZfIKnNrt5j1y+7rExQWb2+Sv2VI+/D3t1166v6sFJBXRtU+aPrLYfHzeAoXb0c3DL5BU5tdvRzcMvkFTm128zCFCjKHNsT/gSbceNsCvVoMZCgwjnoqh40ZMuiKsnl6S1BpJrTMlO7hF5Imma8NK8XSfddtmqDBzvDL5BU5tdvRzcMvkFSYz9yZu1K6x2uO2+gIuZwAcvj3qAKV4J7RYQTtH+ceWQq5aT074gTx8gqcEsXbt5tdvRzcMvkFTm129HNwxie318kDObVAnUBBvJjsxW7/F1tL5Z/RxkFTmaoObXb0c3DL5BU5tdvRzcMx42c1anS+2nIaYNr/6Kkv+yJhXzadb9ee/zpzcMvkFTm129HNwjnz/RzcMvjhJIjHlbfYMuQ5P5tOt+vWG9EN+7l8gqc2u3o5uGXxtixZIYXGCAyJfIKnM1QcytcHZleJbCjXLOkpdI0LSNMHO8MvkFTm1qwlOk2+662fF1hgarAT4AEQ5Ke8FKKOd4ZcOXu0vJKvKxldCkilOSDnoF3qowzlmAOGmDneGXyCpzZqyhBDFrCIQ+a2eONdqMBl8gorQk6eIxG/UMplHgfXwAArFRAq05UEE/gYgaLR7imgvgirKldHPuLTkNMHO8MvkCTWPlbdvjUoEC7iCNzKc+Uw6rpKIH9iv1Bt2L6te52R1YZSgCS1lN2fIKnCtFo9WAqGY3Q2Wm6vlpGmDneGXyCpza10uc9GS/mATiUZlWoo1t3VJijeRj6umDnZMedgcpUSCzHX3hCdPCGT9w4NXkr0XPSUNBMDDSL5xqtKFxachpg53hjZr1io6rgfXOhQcNKyIEagzWju4tOOwU5DYSEWI6tOPL6Obhl8gqc2u3F+XN622g/Sgzk2hMhmMjLdXYqW+jm23/0c226vThpg53hl8gqc2u3DfhgPV5AUKmQsNtKQJnSd4NIHTdzRQs82u3IFOQ0sbhsu3o5uGXyCpza7ejnRVZak3L6ObhHcXO8I58/0c3DL5BU5tdvRzcMZi+AOBQkaIojvza7ejmkx53hjOIwLO9FlpmVQ+CCpza7cyPygVbJa4r+5ieZLtZ60n9kcXE1ocGOUcentrXFpx2CnHQXXBTpA6pcuxmkx9kmvyxyDX9IX6pelpFSG04aWBSra+Twr3W2cyolJpLhE9mqahZMUXsU5uETtIXHAYo51cYzK0FTm12I2XYTPhbCpYHTZjBofyCiK6DYfe4VKZ8gOApKTZvLZVZ/UPjelrVIjQBza2M0TVJmm0S9mRp29d3XRUIbkRNc4PRHf/RzcMcx52Tnxo8rf+twLYmiTswZZnftxhKmgcSKZjXhpXi6UaaG+Kay5XHTDY5OWAebtzA5m2OyD6ZhIAbpRVmONj5Vrw0rxdKP+LAps82KEt4J+3da59VgFhOQXqDm128y9OFUWOIkfIbA16gi9jvdwvnpKgK6j3ObhE1Vu1rxHIZBudDyads3mWoNAIwvGzeHRP4qe76/unZVJQygOQq2JCBYEnMvE0Cgfg8OBzcMvc0VID6OUNAyt2sBSOSkbZCwd0ptlX//jle7JRzt8yQVJgxM9+tfBb8vf5vpbAoGzZ5DSw1F9BXKf+Uu1/EqXpY4W7az4bR1lcNOQ0sdLSyQl2zkb4t5Fm/1M9g/V9sOfv2ZbE7RufEgHqFxYU6j2hcblAwl82bXbzD/nWwCaC0mu6zn6Rml29HNwy4cveGXDR9OGmDneGXyCpza7eji7hsu3o5uGOY87wxynpaYOd4ZfIKnNrt6ObbdXpw0wc7wjuLneEJVBGd2Ck/PJdp4/7wy+QVObXb0c3DL42xbPFC49O+f6nNrt6LR/oqZj2L2mnNy6xJiTHVt52htj438AKZLXFpyGmDneGW7gqNcSPnlTTllTMQLmbtk2Of80M4qyWuLSNotI3+twMHDwb7+kFTm129HNwy+NnTh5OftUh5+cluRxD+0oXFhEps8ONnHbJAUbJbX1BFfed+zYqkSVvUayRiKxPzU/Mz8H4Pwfg/B+D8H4Pwfg/B+D8H4Pwfg/B+D8H0M9Nmg8RJtWG6rK/DHYLzf6QplCXMsP4QNhKSRxBQshbpoz8MKEmt2vD9ytVIVwHIf2pdyWwhfIKK0JO8vQKGfLAuGiA+mZKvvUFTWtyR20J4ul9RfEpXi6X1F8SleLpfUXwiBv41X9djy8FNTepMOqAadBJHT8Rx2BM7Dv/cVIGyF8gorQk7y9B78ltNOtcWnIaYOd4Ze4JTCWqcD7Dk8VbqZqN4knEXfVb22S1w+oOZRupg558UqMxobYaSvwIvh0b9aVVDJEmjp1/loNjhpg53hl8gqc2adBXmESYrOVSAS20BF2H0330mqUrzkw+DzRC+QVKDyhcfhzBxK+REvkFTm129HNwzm4ZmjplTm128y9OGmDneGXyCpza7ejm4ZfIKKoZe8MvkFSg8oXFpyGmDneGXyCpza7ejm23V6cNMHO8I7i53hl8gqc2u3o5uGXyCpza1Yw77rKc+0EvkFTmzwU5DTBzvDL5BU5tdvRzcMuMchHm7FIH/q9GFGY1ge6P5SMtZLXFpG0WnIaYOd4ZfIKnNrt6ObhBQoCaWu/KuekD4Dt4NARor3Fpx2CnIaYOd4ZfIKnNrt6ObhlwS0bgxnDbeMGkwTxiuNQ/58TbvLvVAVYxCNbvmHOewhfIKK0JQuLTkNMHO8MvkFTm128zCfO6GjaSft9dAiPRKxbZfPxnx0RYAlx3x+rOCpzZ4Kchpg53hl8gqc2u3o5uGXDy3WeiwShvqWXGurT8PUn5yxMewTa129Fo/0c3DL5BU5tdvRzcMvkFSZ10YhMKg1BkTb9KK4jLoleyLm+lcPwy+OEkiXyCpza7ejm4ZfIKnNrr80hJjtpZP6bADgWhFNn47hEZtz8giArmybwy+OEkiXyCpza7ejm4ZfIKnNrt9ObTnJ5SpTBzu2/+jm4ZfIKnNrt6Obhl8gqc2d7qDm129HNJjzvDL5BU5tdvRzcMvkFTm12IgaLTkNMHM+lpg53hl8gqc2u3o5uGXyBTd2sg5bzbJxqMkru9hAFBeyhTM3t6Obbf/RzcMvkFTm129HNwy+QVJKl1oRBiZXAJ/CmnvtvjFuIcrJShxzcMcx53hl8gqc2u3o5uGXyCpzNaxoOi6331C+QJzmuLTkNMHO8MvkFTm129HF9kBpbKBeDrAQcErZCvtyz+fJ4fWypYmHAKpSVhdL6i+JSvF0or0mxsqRpg53hl8gqc2u3o5uGXxwsYVYIBEznubYUdBBal6aZrw0ohza7ejm4ZfIKnNrt6ObhjUbJV1R/tcMa8whp7zAlri05DTBzvDL5BU5tdvRzcMvjdH/uq2Y9XM4StB80mpV8uKWza7ejm4ZfIKnNrt6Obhl8gqc2u3o5uJaS+QVObXb0c3DL5BU5tdvRzcMvkFTm129HNwy+QVObXb0c3DL5BU5tdvRzcMvkFTm129HNwy+QVObXb0c3DL5BU5tdvRzcMvkFTm129HNtAAA/v+4cAAAAAAEcUkOr8XOpOEeEZIG79fi7TeXg5R+OKpi9a7VsxW+Ki1EcvvttBwkMjGDNvUABzHdjfMq6aQLj2TYlA6xG+iQw6SK9U51gX12TmmocdSFOhgA6/GrffwtF5AmqAAUCWaxXyUqpsWiRFQBDaimDqa/4xG/y5mH9SMGsU2gK8CEx+UycMYp/7Zq6UPYV88YOLApTwPqSEpLImtEj9X9ks88KrcCiYpkTIGVaiq0xxpIpcwpnN/yWOpfvLaj6R73KFYsUElC+QZQk+F44IWDTYuZ8MNzbKK0RfWlCLodOoWA2/Tf39VewDLoGdhh2/SQt7dc7vcHGqb63kynYfuaevsbe9quc/VLlgOmiUAkI9GnHgInssJrBWtf6XxNcP9V9pYHYIKtDN13bfyOJVsbb10K8djaBpYQfHPrPkveNyN9QMJbkbzw09LZH8nUQl5t22huIrceaAAAmg9gAeHdL65Lfa/c1ANXRQLnEOmFcY7HDnQSg0gdOO/BCm9VhYEBcPhA6gKItVuGbaiB5+Oe33V1Kv3gJ/lvZyTJBFILX9/OBTvJzcovqKeEFYNagOLDgAAcSSmdxdBo+c+KxFNtGEcWYDZAd7/ndiH547Q4lmfj7QQSDnm+xNoiaHHlcNhGPTAEZfc9OYhwKGZkkoMvoJeliAAaQdCAAAAAAAD9+jcpiHg5UftBr1S1RF1AvSG4c3QXtlHulwdp7mjY/wyy0/yn6JCn0XPx5gQH72g/9o+03rYidqtwEZMymTHrC//eP/jBeE8rYZ9oz/lsr4U2GuYhZj+bnQACv8IGVMqVRAEbAXkJ1vEs9fh9oFaxtZ1MlQQpBwulXmGRKJmcENeQPXgA/aLi5lDDhVjDsBAGgVKrvBdsNhruq8WD7xKz8VIEixTF7nXO7jB/kHBlwmC1ZlAopOuCjDmYutQymiS04cdbNpU9F/nUsbsFl8ngAE/wJ1YkXa8M2e++h8ktqLUOmV+kkAWN8EVdomRiOAPaieVd95dT+ZEJGsr+wnak0iKkshzDU2/knnaqtruYQJ7xjhMNgxvy02SsLJuYy6Ha4vFrGhwduUaUfejYIf7FJQNqnVHNBBvN9vQTmlbF1le0KgpiIPKJ4Q6NwR3ntFgWGHSc9ZGl1KgTQzSwuRMcwoRr+JvcWvfFwns3xnVMqSLRXd+Obl0rpZQUftenDn/3R52N11lPsh38+mbvJlnYhjHXjRiKDTSR3OjkESfNUb8foRM31Hgepx8l6fjpdF9HNwzP01aLx+WYVI5oeDvZtM+nqFaf6NTEa0ydPNphSgPVytn8l4u40v4nGNBBbSGVrcVQ0L2qRpNXl24XFWTFfud8eRyCFFgI3FWaS1JXu6x+NlOO8w90ubyt5V5zIiPc5wDJUZm8a16mRmmQDvnvSlwYp92IQbsFzoapt2bKaPJgV/NOXuv2olX1YsC7nbbWZ9t4oAOi+xxAFvEEta9WuVYyem6O6ZQy0/qhA/wM2nE5vCtT7JrYEbDg31HkaUaeEs37DtLAuGlBp2HaLa5gnfn/pMJja48SQfvLiOciMCb4zTR/PrYAD0aRgwk/SI2lnHmgULvUAkFaEsuuQ81Geok42RbcXJD92xlccfFsE8gypvScZWNd9KgUzz75SZqz+J1xosumQ9sSf6t+KgxDwWYr0YbppYzU1mYzFzq60RYfpsEC7Bq7IoLthF6dzellrsz+t4oETfyrANV3P06h1F5t5XuxX7Xva+uUSWFcpT5rVifBEBNMglnr5982/IqvD43yTJN/WNJY5rA5yZKKm9R9b4uSXiHihQX0uqAHqOnpAp9cZA/zN9gdF0gfDv7vPte47b/82IKU7Xgy/amo/DlKq7P3CorSSB1PL+3mVbYCHI5kBozD+pF0ckp6/f7kHU0kuyqzVpfDMLt6juDnXzn31KeabqjvO1vNjj1ZfzWzCYwh/ArUpIygmwqXyN/fUQY+cdH5jQQGWbG7k7wtmYI0eknNIF8zHbK/mKe3GK2sVCBLGbvNpAFjlPtpSjiAVAsL5k0wDUC5V8+dy03MxYPavEWN7uKfwUoRJTI4ft0XgcOsGcMX2FBjBDaPLW5xEFvmHIK8NsdtveOZEQvNRultISiA6zG4NUd+x59b9bCu35QhCQJMbnpmAcbx3SeSDdJ/sE9Qa7wzyKaz/Z0VO3BYtq01EuTN5qjdNEzkuXreiLSbhIUzASUhb77tgCKq+m1qBSQQzKn3Go2101QSikw7J2ZBQygCDD6AjWNfgB9+Hgc6sOTAAC7Sef0YR3NLQkcZwGqWWqqPRA4VytK8Ii9iBKGMyXU+K4fijy3hhXzz6W0wctzlWb7KhzPKnWtlqtga6CnUf+cw3q1xaMtuvBpqB6B7YYXAh0rcvwp7f0isUp+/RkkzohxiedbiF8BxSlsdnyCVhXDJWBi7b0Ovf5tDHFmh7aD3DFhe4UUx2egTUlXaGtBodKQQGKEFzmaSeiqsjB/YHsEz1ruCAYz1ya/zSK5/LlHi1AbdSVOlRCAZ2rU50RU3geXnmVlu5frQk0DmkLuTNM8nrcAxuI8mbrcSw9TWFbpUKBKb3oyKgROql8fJ7L1Wk2nRrBowQXYb9Oua/JDsjS9d1ht0VAHpE/JnjSwzIGSYpyYV/3jOIZMYIJ3KwSCDRFMfqwBUAgfCYYdXiw5/uLqsfkU5HWeKoQoWPjd9T9LoUgd+uo7yCmDtx5pHr0rooNlmoO0qLeONGzbV02wmQBCLLbPm9zhEY0yaObf0F0Euo1B0AMI4Fk8FGwfrCuK/9IstZa7gZOO2iQl3Wh3hR2/97eJjMwn5arE1/cHVdgAGkIJiiQi0Gbq/MjNlgoVMdoUNucQinIG9m3nLKua9r+mctLA1mWus3Z75th1/TEy7P/4bs2qiF0PRL1/8RBNsXPz+1AoV4RAtX1E1YZzTViJBu1IL6H4wLjtVuBX9d06/mN7EbZ9ydmHH7WyP1ocSFstysHqMcrO1QUQvpdpPJVALekiJ2nKfu/KWeUjmLmfxHpC6rlZCKAgAAFcE2NW9AAMKwOTpvfj8EVhuc3pkaP4IJ6CfvoTjB3IKB21shT9MY/i+UdQtYpZCR0asF5qym8v1Z8Yod2zs2Sjti+03gW12kxsawK0Kz2mBE7ejCBOxLizbjfHz/2coYxbmahNjadroredVivi2GCGhHT+tJkzvxry9FcpHwwG1Wud8ulERiMRM8mDSLDvjVVuEu/h+SEjSNYlI7ozHZzAZCZoNCb8C9g5/6BHLJAs2i+4A+IfZ0OzZIVYwcx/vxzBx0fK9xmfA5xWw/8AaKMASOMwk9TA3C3+3xUWshhTG0fTL6zSIbTjw4cfTbm9e7o8z/0h7ChMcTESJymhJyLX79tXu8f6h0SDwcjQSqzfcYCeLKwshm6Yr9F/5MXzAQN6MGpeEot/5FWdh/k7EHF7QLVfBm8tpUPndNtSc+pcF9C/i0Cu1unDOI2r8/MVWESEBX3zu+DFxoSlibn0rhqi6a4tCzVUk8S8/6+dvimPgjXLxzfm3eQnNH9EtbrTv9kj5Rm2NP1B4H2WESktX4RjqyNrbK7wX8o5/BYhNUTYyuq9UhZPMBLL4xA4jxPRuicWtcSN7NQAHvOAWcvkvCye7mKD0KvRisOwjBI0TDZAF2F5rQTn/QgppQOaQLDwDnBQ+xyGQ2BEtsGQxruBqZ7wDTDmWwbSp0RjTPTn6+mO33II+GsyUipTIKWf5UxgQr0DxKNYcp41f1qL4W2sfuHdeOpVREH4M3brXYPsPNXBE73vxFeKNWHx0IQV9KGzaF3+yibHQ8yTyO5IXsHbSj0xmNNIoLmQ1HZ+1yohm3HcHqm5kTEevCdwyKOvQkDv68swX59pokJ0frqh7OKuq4CHsUDnBlh/u3lS2U4Zv/K4ivRhVC/OE3Lp0V2NwHrlQ7gYuN7sA/P3oZk1zwToiea2LMovxtI/tvJpbH3qGEQ1j1tmVdlGP1DOGLVqHeRIowTjNF1TIcmet4B5zS5wMSjwfeO/w/a/+ND/lKjZOwjCjBoS2pZwjmSRoz/TvZZPEEpA3JEH+OWO0usvxAzbyJp63bGaX5bu122LVd34JQNaNM9TnLyfhqI4GX9wJ+5ueJVObsd54A6zgkSz4Z+oW1h08YuCl1ZNSxm/bS/ghGGPNLUrKLMESoeU5H6k5k85hLsnxFi6VcKBj2QSiblyKYLYAYurBophOjnLLz5MSRsV0xF+50AXdVDdU2VQcIssopxMwo3n0SRD6Dw8uHWBMWDryCPRjmcFgGXlzo7Ho6F2us/42Kj3CEMHS2fOrvCgiMYb0ZKiK/Rm86SkQfAgVoUwNuS1gWamubZOYSwip2V5tZ4JQ56EOGBI3csbgUfj6RCJgMtgIeAdY0FdLYkdQuT+L5P1CAUxfriStBUdminSqCPN1hTURBtJbkXVodwdarJx8wD4w82ArMxqnhuVgPfu45OnO6RszmGPeyXdk1Jc0Mr4OMock7Q6zdscA2luMuEyzz2+UAA60pWJRKVXG6yKApqqvFC//544fKYruEdpeS614jGkoC9LCzPDrNrLKM5XhpGPjtg/UyZZP4IxbX6m07ONo/ZyiEl15VXPUqdrY/N9oKZzlCVyNq86kJeIFg5aba4ocK5fSMzUCdq9Lh3JcJXBwykQqzxokFFRGNun9WmAag4eU/Bm9juqvIKQrxoTczRnRiZ7l6iqVTs+CSzJZ1uvHDY0MZaP8C2JlFyk2kIPXdaURMJOGziexBtoUYz6Mjwg8dmeWk/8yEuO2WaBeXMswR86MQTK8yI13DffjPcq8tfzlKO5Jx1dCJzUUYS+futDVlylXMAlc+n6wwF+dyJNVbHTydTnYKhCzlhyL7taX1pz/OTp7cVy7/PWQuujpkNwWgINztjN+kzjKC8CyjFMo2j9SDit4m+8vEjHAHDwTG0gp3TovLf3dK0L4soqCraQz1sa1CQ4cLiHaQTPh8MN4vUrrB8mPbgXt+wgJybrUNQzJlsymd5PVUdL29JTUtm0TgSnNNgdBhg3G6siAINr243OE7tOeso9FDKx5jcpLG+Bg4HFVNpuBDwgtf/6m2rTab7MGCZe4lE0HRgr3G79jKM4zBmaOBGZ+Y/KJWBhoKV3F5D7ZxNrDXZ9Qe4oKoCaXt9O870V3Ktv2PufuOvcyt4YSyzilTmm8yHrzgYaMW6Sy6FAFXziqG+gTzRkESo+yLJEau0/YnCMo+6AGLRzfOk9gXZsgur+AX1N3OzkgQsJSHvExcfy/47Uj2qgsJieK2yiTjR+SQkBlfIpK2sFtjfccuZevpmD7UXmt8ImCZT5Vpy2wrN98xN70+UpaYiUOEWGlsPVwqD8N2zmWX9cUDT45FNv+/xYT8mTSzha8povxp12W6aEHmT7+GvkgIjKm3YPVabt4xHmZmgD1PKmu89/hlcwdDqTPijlOMW/tv8bBSHBav5NeVeEPyLGWGr3NxNLYeZ6EKzEyL++/rmeShr1jyuHP+WOAPp/Re5d/vxJGQPHMFaXRrAj25QcPwh4v5maveLjzG3rl2vDNTwDe9EsYEmrkMI3dMrWy+Mg0ea9tcYJFIEO6nzL1MKoT5uES5oN255NeaYXyLJhunD0qj8SWc4R+nvaZI8FtFkF3z7rRt5XE2GLXMgFVs692W1vBpqa+XFMym7G7A1m7GfBHFZWzNd83RHAS2HGCJS5483lrHOwa9yVi3PTCJf3ErvaSrbBqCJzYELOqBlJe4zy1AG+L2j+sDgm/QvchjJzidAN8ArC27ccWoKmZDoisy+mASTAlkTp5sN1Id2XEpUq+m3MtAysjXPvsgKYYz495myIJ2yeI2y91AkcMfrGpf0bDZeVxEvzQp2mrJSm1DF4b0DIq5Tn0+QsMIjxfXj7DAQcQXs1GhXQSUXyLoibiTSL4sox/vxPvo+P88IwBxz0vXUzF5qk2OJjaaxbzNWK3MXlRzEvVn5KyXkknJeDaULibRFViIpGQZSrUwnOSQ4PU4mL5RBCBMnfpNHdsmdCNnrpHKHssId/aPJSAsgYeotfycfrN/56w/4k/1Ed/ZWzaFVr29vdvo4ECzM1MnWcJwVLb7/Q8F5Vs2IBPOpSN5VLoC+i3//GhVvmagLhsmLfp4dyYfouh4yJlgMSXPsz+ct50j+ErqbDcIyn7Vrsuyml60QdaFunHFuHA/lo7fKHF83BRKu3NDrnkWqb2G1/2vG59w4EyiYv6P0YsZzubg3HT3fXj8kRQV4YJH1sm2g/34d6GEZLAAQKtJpwArw2ZxWb7/IPfE3fSS+V+Ql7tfbBWD4uJII789E5b7QTqD/BEbwW2kqORHsP2oJwKGqHI/ngmQ2n+4tzdwJFdxvc5NTlvUoFZhnIDw2Rol8Zx8LiX6PsReEFWFvhFI7l6K8k02BKD2arGpuxoIoeLJXaTH/yb6uaL2b+GNdAj10tC6gMb8HJybaSik0xu+AVy0XtYh5ZkT3wKfMkL7vWPOFNUKlheyo4E1ZpxhmsUEewCZdcGB/No3AqqxP8NdTWZvRFFZRk65Q2/hL2gKoZionQv3tsJrl9vbti6SreUh+KKFntTWuDIHHKAABYSTAAHTtmZ1lq6kddr7P2cbskNR2oQgAucsS8879NyL/b1XdLoFUbkFd34/pU9AT2YN7hXXSf4deB0NYLYlg5RzvPnR4nHAqYJNOrjqgLQdkNdcIawtKaHuEulcCj0J4Y0K7V+FBhk1fnULA77jmhkSh5rW6dcY+sdw5+fH0qbVHwUJ44n2kHhqAXTqbAFE4CGrEgM4BT+Ryn4I2xf1YOqkHPaSbt82cakpbQM6AkX2z6BVCw8fgSLxCw6OsVES0r5bBOaLeps1/gTNZkh4HI3Vv+0eGcxCrD1SF/a5tjNy+wYzvtijYOcbIAmlkFft8Xb8tTxU9km4ngoi6Fb/FA1GEYw2SNmb5wACCnAABT7pHy0gxuC5aw1hRHSrMFSh9OXFED+bEjRRa1jU9ZVGFGB83AixtdAkGpLphLGPVrICd5Caas40mkipW+1HTHnSYYIu0vb7btKbB4XcuklRxPRTHyJPo7G7AuGDAk3N29P60hr9G7Lyu/V3YujjT5H0qylB5TrUkX+UXkuYr4DqVdY3dqGB52Ngz67K1EyDIMyc/PqtAUFwfU3kQ88rz1/LiYDdO3GW9WbSVr+ztJRuLW6De8LPIoG0EJgRq5+hA0WellsSpksRJeFtBJHmDyJk6A4qXMUMugIZLbwL9fxeOAGmsXSUpiT9jMKjUv9hG2rjyIOYhI1xI/CI7/nwxjEdUpUATKmDxgUkWizEabIuUwX/UHBH6cMMErU81QpgRnJSG6BXGCWoxtpTH2Iv9bJvWMoYXYoUj0R5/9sMt0OHGqZs1FGj75A6GPvZFU6alhh4XUFuWJrk6eqKvJhKdOHZU25QJLo1M7bBg6ejf9BAafam6zycBS1dGW69AtwmimdkVefifqhPyAU359Voyv5vadrkkRPNPaVfLoITHwDGCHm47dvEWtTRA88qjW2vemib6hsVprFV+pRzqHU+itc+hVNSqo51u8vgHi5GZYjH3pw/7KipBhfAnd103aI/IpOJTIu095bJ1K1GsARErNr29nTGWQfg5DeIfhYi7P7iwZmpKtkbiYiCAB2LRS6EZJFoAReemK3/2Dx0U9kHj0pc3s+E/Vw6lB18DJFjcaDAr6CBdPlqoclFF4wLCUH3sZxYPyIkeMc+T3xbWL7WpMltbOngxyJK4ZmXWigN04bAiFpmuMeuk6zr8dfKvZ4y0o3RvReYCeaDIjdxYm/gO0O18msFzNUyeWWz9PkJFcfHKmb3zWwDMjfUUPbjVelaN7AMBQ3hD9dQ5PwGX8340ewsCnxgk3k63NX0XUSut4heV5JnmqYOVHNjyvwo8fB+PmQhsu0IMqJ4tguJKH7b/5SxJPt/fOx2e688zAFmB3GkRY7+Rnqe3E23+E/3A7bcmfXcUVknOn/H5H8bkXlbqgYzGESsfElllXB4f2pGCcNWEVcXRsYrTXDB11o/5z/nTyW5zs2qbcqvlelIVS1+FL9zL0vSYVDFLqoReeMSnPwvPsFC9gX0QzndsJaRV48Cm/JGDTjJ16n38rbtK/U6VgkSLJgdmtgZ2Ei4WH90Mw1/HNLRgjwB7zIToBvwssux5KcI3Hgz5RBzqKL7m+I23qlKswtfwKdilSEbj+VNmWlLzO1tW4cvpSQKSbb1Wf2OLnKccgmg8f0sAsHxbgtPuzLbQ1JpRAMVbVkmjp2liXU75R1slOfc/c+FnPx+NQI9loR1RCdWqSTn3TOH165fq60/bjEO2oxf8LrrRwvpdAYTl2F5fEgDhbDIwk6PubSIBuKlQ96emGb6mec4a/gPV/ATT2sUwTB+kOj78plG6E47rrhHPf8qxu6m9V3VO7UCR6kfkaNQW11X6z8EqA92mnXcpvDr8gh8EeynnOEhRW+bscCtt+83i0D4GyvTXLKpgU8wOWHRs6k025HunxExp/DrtMH3wNOSjhS8+CHxDguShkDxTBA2sqVQX9ZJMSXYsWsxmbVrLWii8XegFyA2qVy/Ft8pqHZ5uGNMYHfa2PPNgIqN8DbjmgJwjf6i1GqmgxF18p8GyqcfdEnfb9+ZiOoOzlRZjVpqo6BiihSIjcBcShaGs0NL6175mZwn8Fhv4q2o6SPTsA1AGzrTnkb74pHwy0WBG7/HWkMctP1PC0C8KYtIkd4vDm41yIM/F1Hzh+2Fr5X/uO8PDyi19Qvo07s2MWjw9FCjanoMgzYCDt5LxzLcZ/Ob0ERHSiIXg9QcHK6BKojNazPua2HRRwwghwBwO7E0usuDqDcwKufuCEqwo0uo0X3sHIN7V+V8KbHmqPk2F0M2m581aWd+pPX/xMPg6JoUf5Vx3b8axF34WpDlvzGMIeavuP/5w/x2coXDQ+vuCgcPnChydsGtaW5vbcOuD2MHd9nV3vNEg+DV93ERIUZV+lRaKTq6kB8eB+uN0e6wQjHpGwBptc9/sUbDIagIqXkKNn9VkpC88O+m2SH7fPvkPeB7COQUxB+cLRg/i8ngZcRVpDZvtOF0Gcyik9FJ5OiKe5qtYq8X/mAAzFN/LkPxAuOvDzOjf/kCCroQqNPAdAVY78LRj2mPRSbF52dpoU62R74Y7mFaUo00MihWtlobV33dJyAIzs7XWUlS/CqTZPxbSDg8ApIgeCmlBBv1iEcBtPcV1QCJA2HqC5ZNI9U5GviUkWSjpR6JIJJJCHvAESakDCdsn7XpO/gRTKDzgm8BZq27DiHOgZ0JUB3nihFXl+2EusgqQBmJ2VlsuSSmPssQWNC/vNhY2+8L0hYCICH3XFf/uqViUOo0cN09yknqnPYHQ7rEJWPMJGPXJdntOQT6II7SKmu04wCqtkWkEgaSCStq9jlT1M09wkhLd3T1m/YOM2t4VPIVrVNApgZGOzq5a006uEOHntM/CgyPPp7fEEOH9mdOyaBNH1L4zWzphshHeVOIfzt+q5I/HvkYr5+HfY2oQm2V9s7mSplU1JHVtUUw2dSTSJIsShQBl/tGxCgWDsTcsU/8XZP91y3ky1XD89DDctHmf2rKSHo6uJMa5nQteEENHk6Rm7I+va0N85KeJp9u+ixJEb4Pqm4/GfBqOsigK3hFJcTYptEYvdX17CRRWLZYiuv5xEbJCK2w7kLTF5gBxoOjIOFQsl/2kWszKXStpT8HT6PQW3YLtTK8LKVHRi9QaNTGMeUednm3FCQS5jelUf0lGfU4yxDqvtU72aBI3bgd5CI+acwCDRSS1b3Gyv0BsIehJzQKajrpH5P+6sQfmsxZu9oaknYEki4FZOaiGmZb+Q2+FQb2SjuQMq2MOtKtgU+tCqJtnLZOceGFMisgpag6vQIMddsQmoC15LMrYlf3mbescUGrfu1OCD1YKpJI3QQnQPg2xwhWUmcB8cOAnm2zhExnmy2HJMTJ/sat2hBEd5rhP9xw8mpNs3NgV+4EMQNwUItBT/Dsbel9AHp6VmRLb5QmXlg/CTtTu6pPiBJZ8Wxnb8LrdHbMd7ygb5D3A0wfZwk8jsTHUGKrmScBunYkF/p07nIeNU9v6/GwwSDizeE/JWHBNolT+G24fkUpoJ+UIJQXrkP5UySr6GRbG54ISnC2mXOu/MLJ4JpFe6urYziyz4M5qI9NtGf8tJW4Q9SRXx9I3MkHhGZY5TkxxF+z4teV1TlkAdos3OVsXV8cRRUMny00H7M2K2OnNtm/2AZQOhnMv7oFh+wur0tyCUITy7GztchF8TJ3QjDSoFgcwP6T1pyIf4Qnq07YvEuzXqDFkdJ3j0/atZhzvmHuegnD+OcgLHr//EjSG5VRI7mOwi8O1O99zjXRwuYyeqkn+H7l/vits4B7hnNQpkUjxLmSZbhDPYv8s+p0TTGp1/j1DSSYjW43xc+FgoKN78b/FqjX7alq8tJ79XfmII/twypVG6CRBfiWjsmaOAeARGrXw7zXm35Ta6ZFS0TUAx6FF2t7/QBfi75Ypb7atpEYZhGwe1ugst7fJMU8OnEiS3Bp52SbedJxuQXX3WuIfTTPwzCP+Kje8glO942agvjhV/4MJYje9vz1J18lO/zMAronSxLa/4wHv7Xx1vKbfgd3X/KpVS/PvgRNzBldFQIIqHg7qP/gEfZVYjltKulvcVeGxumGxjiBbuWqZRNRMrj1f9QY+HZoMMscHobW2Lu9FpSg6dU9wbLPmCagR8/zkU7D49IwH9x7dU0aIJxeBWjhGnNK8wZ0qFLXiArYvBwyzGtQOC6niUFpuEe5dHPiZsQBATw9B6wv5ABJF/oys5IFEWFA8f2Yse5cKLgqg6akpgk2k6JQKpt1HzJANaaRYZewxP6lDrFtRcN7oeakRBXgODMXM+gRLbQBNme9fmFJ3odDMp7PYkaa8fWtEQr+HuwPOwwqtv7EQXUTUlkbhVwUahne0OGCwaBMwc70M2H2jFr8fUa8Kial1DsyyTIua2dCkX+hcVz0J3A+XiuJBTL9lt8IoMrvQS2gONn82KXOBvbwDwHfk25ZYnAK/W6NLvqkX3D0ZtRNwTNowebmhRXsLQHBBd+oeoQj1kWnkoo5weBLTZ0oA9X0oq8RPTJAJk4F24/44VAFWsCcxoo9To5mCPRhq7BIPSCdWXVZYqrAgMKh5uADghMYMBqU5sBGbRHPWGkXTWPSle8/YKLDwlmgfidJhFl1a0nBPo5V7D43AuYgC0rPypvj2kASY0AN7WPDAAAAAABWvurvF07gpkSg6pZGqTUMhlqPCVzJA711ieJEcu/S38HBYj6VAPgsu091xvor5gRKYnUk6tsrRZJoZdFG6B3UxdWna5mPppTLxNOVns/WgS+tBKWxn9s21xaRHNZDegy1gxh8u771Cfa+x4TIrEEElWP+xCIinlYP7JOVJkJpT3ozG22w3l1Wh6arcmnEH4dG1WtfHPI40HwSflbH6KISXzAnHkkPN3dCHDe9HFZjFxPHaMy2O0SvDZZwyEl5eceh1RRUIQLI6EvgP33WCzU/7+wiWANg7IbL7oiFEsVQGkMaPpodK4s1QPkTgDuaX1lCOT0zPRX4wEdcyyFP4eg7n39jILr2mMKyjOPJawu8kbY78VF0KEwg+0Uad+7/BTTj5JTm7wV+PR5MaXWOrfqvO5dmzaIPtdBM2V0Kk5gyCFwxAXjsN7dqnwrbHvy13+OeohduC490NH7twJeLxffgCDzWXeY56sjEiUxh0rOjk7BkbP3PoSQCuxwTbgIjSD8dthCM6A+hVFxaxAwo/CohRwExFGZtFVRYGNrNg0nITC06SBQ2mZgi1WbwtoJHjZpnpOJeAFkq805HBPvji3O5zfSM13fmqRrWZAjlaYKKeWWADcqRouucTuXuZgoEpsUKXZ41xuGVNfKERI0gkgVj6stgSdz76nI5H/7AaDAcTBqW4UQpI2Wx5M4Xvjnax+QMWGasMLybZiwUU/v+3uwRY4750xy9B8Wtw/iVX1Ajf5jDkCn++qMTavVCW2BMEs6HMl8oCROZsYPfn621A/8rZ4p276jCmYcbdf4/JlzeEC2DFHHuJdNNwijN7Ley/26jEESHs4F0QwC5o+4PzQ+CgcVMnXMAZ6OZLepbJoJsf2FI+o0Lw/IK/MgEkKidkfgpq74t7KwMMyJKp+VYO6+knBuJDw3RgbDMXuTh3UpJ3suxO9MLyyh5Hgs357+IqKg8BbLkHSSmvo+9ZPWGHWRkmnSCZTgqtOzkUmp8qgIAhFWlCOjYhx/4bNeJzTlRg86JlSI6Q1pHTTHBR0wOPubxtmSt3RG9hMnpcTyjtT/PHsl72A+OEkXv4nX+eDAF5pi3E9WZR+P2FdeKZqJ8abiVDWkVYVIKO4HKPJHfvrmhWJs9KJ458qLjM5Ish/Cv9sD68ZJhIAAAABhzNkVzXSpo1LNQ8gq7sL/+p6GB932Cp33C7VNsQv+KNktLZoiXSdy9u/Tc86MHc3juuaRXM+xzby9TibHFH+LMxz/FVD4LqnJsEoJfdYRbDp7OjXL69h9g9cA75nuFX9Byc39HYqf7Ba03TQMxg2WPVTyN9d+5B8E8unwpZJ+ibT8wD3sGf8YH1vBctgEPvl5GSeTF6/SRf73By+hFf2uOepyLf9+Vm8W70pZ1+xZe+FRUwAg7MZ6Q/u1rIM8H5ZCFeVeuraxrtZrO4V555/K2useupsyye59yORdolWd3yT5YoPwZbbEuvxXz7HoX1rnGgDIFbMrEeG4hAWZoBym1c3EOQQ8AZkc3f4QNN5pdWLJroI9GMp0p8+vfgWTqJaTqKWW0A5LQx3VdSmrBUEr735Ntb11CVT/bKVNd+sc9D/fMf3wV3ws5AIe8ZN4u6kvHbvZapBIBwzThlnrbSZ1lPTYkccoLKaJopumXzlBGpbs1QeD96swp0VG8q6m9nVKGrIJPnN9atz0rptUWRX1cHDy22JEMr2Pv2jeNrilxeBwu2QF8OyIDT0ZFBWsuTWm0hveQd2ooJMpAMkSZ7BnjdPpqlUKrJY0JPQU2NZ2XrS997wrhFuulhBEQnVk80pxO5NhcRgXNj+2i1xX9bdYaBZjgE9dKBwGnCTNHqW1visGI7sgzFT7F2poUrRALdOSKRNceaH6SaTtnZGDyFq47Dhy4g+Sr8V14um9DX5wlM8CpwQGilIksByZhqxB0tWTRf9h3x3KGugqwE5Rjz33D3ULoMViPFgb/3ki/INhJ555cL+WoMDF5rFL9zLZEzERKTEAJS5MYh69W4i+M7jTGCjPjxzgA3efXc2z/Ev7EFVvju4g/QlJq4+TgwO+sgXjWITCsg/f83Ft29vKBFFIi80t7cZW9Hu3Isuabx0bDIXaBFLlsBkAblrq9ZYtDxngG8Q8Y+5kD8kRrT9GTytzfuO1rgPN+pVk9ehSqzdyC0xGrZutp1cdMR9GrON9olG7tMLsTdFZEs3KEUNtGHF8LEqA/x40wV6RR8gnCbhcoWvF3AXLN1Y5/Evp/WEJtUyKK8uHbQ5aTmgb6Ioib6ileqfborzkjWS9JoIsQiuwxs4mUKgpfhL18js2dJxlhyXKc/oUblJbl/iclVZ4WeVkAcaUTc4z9OPl0bzuCw2IQl96Tt6lcpkxYxDwenuCTHh5JXlZodZoP8px2dkkYpDB0RSBGrGkFkGJOfj1JYW+4F0gEmx4/gT2NEMxalYik25tEPNU9oGPiqFdK750ddpVtaLgVtUolEULiheLd7GABlp4021iG6J5V6Qd36r8GEM2+gPqaVAa1ehWGaLREZ0OyEmcm35/oRxwwELOFnq874G/nhCpGWYM8j9L9IkR5n6mujEoWDeFORfXZt7MJR13htDp3yXY0eLVm1rH9m3fIGYzm5K0LI7jNjycJwAJw+YhKpBU5vZ+ga7CBL2Dii1NV8pFaYpUwQEpoU2xXEqGHXA2fkpVmqbc8T7+3kHNeUr65V9PCejDMVgK0Xr38P+i5OAlWfQ/koSViFa11+TO4oNWXZirYH3jCKyJHKgq6up1eIBuAJw/xPwpB8Gjo/X2x0iu+4njy81MDCuaqWj2+jyJkfSBOtEMc7DCAtlGwzxS35CosyXyZz9CvN8L65QedNGNV7Ad1C5GKFihKd8/SglJVE1yAumqxu1OXr6/+zbaRDHfOKVPyTYjgNrLrTMFM2LUN1WupOG5fWaNlljS37HcjRiZqiv50w9NP+LTJ7B7fHpv8foYm4sTsVAfY0Vnn17OHp4NTZI2/Y5/eYhLif43JjdG17aYRYIAte4sblJQi195GFg1omOM11ddiDDOtWvD9MjT5oXaRX3noQQ29YZU7b6AiVPz2AikggtKlRZ7+qPP1xvbSdgIpF+eZ9wReOWy5grbPKuSk3EvOB47j5IvLhUVbgFXQFKuAiIYjsB1B3A0yOHYtvQTuP9SgMCMEHByxdDFNOghfHKdAxsTSmbn/Z76hu9UhL5mPdNjZ4S3ByyuWzyMIZhuEaQRaYDVahX3HlRPTfwU8TUXo/seQnLT8sVC++H43FmYv6IqvarfcMKPSsV+r9va3m/dxuwL1yksnDGhWPsSE9UXU1Ey95Xo1eY+eLi903Z1UvOpMf5yQAj0GKW4PGOOFFhGaExtkazKnevvoNJ231qeHE9YsZT+q+uJvY3023Q5oEK7/ZrifbhWWbWAOkJddt8oJ+ktzUMEyKGf24pTxc87wfirX1glZuP7bHHCf8SI+Lsa572lZwOwdgTClReJP3C5S6rD10cfhpKWvinmYIl4Zvx+gvXrkNXl/uRhPk1E+5wTuXpcPIUBxHfNuhbkL65Z6FsyBROztvb5G1ACUGhaN96QZYktVzfVIixJOCZL1C58DixiwjgLj9wawLrEvcMLYFOj9+4nbtR4rKyXjGaOaoAqebYXXb3gkL2yUsJgfW4V2EsSb9S0+wOfAAAAAAGmMCoAAAAAAAAAqqx87Ac2f3y42rjeKGc/IrjBZZAqp4PvR0YkAAMKwPa7xYoi7VTldiIwSQ8NA9JTOHOvoZ0/TZQda0puONYEb9mI1xIHBT0hMltACU9R9OqfL9bHXGtdB+imkFHuz5hhTXrAG4cf1BseIGBYsYiwW6CWgAZmgvecnLhQAivuWUM0oIJc2toI/TvJzco9GijsTEtdDZKhu4EoQjDvaiNavzLDZSJJ2xhqyM+vnPowAHdI4obu0iXyB1wU7vQKoDhWiCl/WiwOnzKaCcpjxVxetzG0Gz7dxVaGzZcMgAO7hkizRBpn9EQ/l6JJrw2u9qdIg11PVP2osysYgBZaA9EAk99useaOooaqN8yTGPP4GBATVr7lHpqU0fYtxAaHwNdJIGSYtu0+Qc2PJrPFW8QpWl+4mqVXWYfWRXMXKhAHqIYk2Wy9gs5PjA6oWGWF0elaCGXFBnVOOnTV2f6NF0p0k/PPCAnJA+61KNw+To6vU0vrgpx34M0M9Wy7uuEQEOJecZkjjsp7a21zK0b7zLTMgRrvpjAEpsApcNmLPCl3ZQk223bwW9UbgfkCpO9Tu7FjE/WEfPO+oh6JSftt+tDHR5n09ebfQj+s4Gt6O7GEd1uBplG/g/yviRA90Jws4n6+JfXqG7FPXATBNwZDwCoWdLy55XNAcZ239K74EDYIFiNkA/ZSEYXCtbbXuepob7WGwPwtQ30Hk+rMGTuPS//P+xgEN0RD4KS+Tw/mh4+pX/lGMSMn9QQ5YSePhqsl+GxlwXTTikT7jyEP3mjJeJt4Kd3Dmxe7QQ+p2hiuTEpbaKpam4K018K6/yhRBJIggbAZ4Nd/vRCM8fkMJfKjnKlTH/uarxeUm/6u8cp+tP03Mn4ZT7eMTxABG3I7JcmApkLlkYL07a8pnJWYQftIyeUrTGhVaKJQQ/u5DxpxKkrEaWAOty7yS079TwHwSq6PshAwrL3+ZBuxJGLz8pxhlyzQE58R+VBqtadmpTvZJUBTBtrPDBWX2ZIXJ06CX0QE4PRp2u9L8jl/oFPC85Imd/JXCPdDftAnxkO/xSnUjiejeWPun//6u/5Sx7PQpXmHpsdhbfwCxbuwTofKaZDA3cCr55QA5+YoLE/HmWBE6IRig2kRgtPRIiNDU9e8pRJJI5nGy2o5gDlNr/tS0zC4rjSRkaF/0XkKySSqY7knI8+5DyMvOkBK0Ck1+V9vvKHCE31JAKUd1FCR2lP8QqGqQTWeypdnudtXkuyPNFm9lSLJYB1rEwzqixsgT0iXTGlozzpCEdmE0KhF/N4YzWduXycOtKuMxkoOpELjKoGJv1vtP/O3c1QxsBTLqyx6xp2JxQlEpMPzLjSLsZsDVBAN6GAA1fhEAqFewcWAuzPpsOVTZ8Wgdpbv9tQJwsbDfiEhbUU0Z5QYoaqu+ouNhyy45QBhGA1Oxu0lGtqcSF6gVDMQ1/5SwQhDjvLLLp5umn95pgO1h3y8F2phdLAzAjQbUo5q4g/Bn+Qwp72BAdFH98sli5nOyeVj/8vqS473nTgks/lSpoknP1OYvEsUApwtLYql0W29/divkL0kyJvGRYiBZJhkM9vnyOgvlbOkIHxubozKFAd6w7YAgBC85h8/T6A2vHnagrx17kkn3s2DM2/18H9JKT/oUOWHyrPlBiTfGdBIRspjMD8Mq6U9elpQOU/j6o2G/es3BQpzd43KMWXCIakY0wpPbzfUFlvY7LmlPC56f9CVMTIFqfsJzHg8dNLsz3G3yCyFf9BGOhH0cINcUHoOZ9c5fYjCQrYiW1tiUF7oABZqefz0y8hZbk+tL1suXm3F5RwffnWXhZkEdEOXhHX6wQ9xs1GUHhT7D1VpfnSox4wmt0CIl43smm2hWS9ypxUenDO6jsDnongwsf5bMTHwnZFa9kdP4zRuA6uLYI43nUNa6tWLSc8BrhdDjWSXt4JUkVlmfJ+s0I96PSXy+xAACDpYAAAAAAAAH6Ssk4kcGy5wflmdxwsyjmYKGj7eGPEUBUKNDrZKAG1L6ScloGKmfrsCRVtDAHUoxGB5JRsA0bw0zrOWrTXqP2/YHe7LSD2W2hHz3TuCasKQvfAByxpoTlWW9OiqfE2iqXxLjDy590xjeh/ibG5a9fwNaKTxM/rD+ZPOdTjJsXiOczpIRWj3bhrhyCwjeEk2se8gChszn0FTngxBWohGDcw09Qbz8HlQBuJLKKJ/IuDBHysMTPrQrLQ/UyZGyq651mIm4tAFMA+vIXgTtAAQbBrQlGjvCzJl/WsVtGzm8YJRIMqOPMIz7BFikloQAEb4FZGOq/HHmVl0it5TWL3Ey22Xi7YTm3vXmDysrkepQCWuHG5IL3UyzmxtmZiKUJQjvRVviTyNDW9mG+UnuL40BIqfP7XerJlH8VNYUooRMb2k9VWTYdVfXetJeVT1wfcEd864Up7QQXHI/vWE7b3/OkkMHW4FzUJj3TXGxiafV8e6tOiJAnd4LgjEBgq1F4hJBqfQ7vYeBwYT7BUErXGiCkKaZlDnim1RZbcCZe96uX7OAoESb1WOIDCFyVx2iDfRi7hQMXNTf/L9UtD04vgBtbnVGL21QQbUPb45ME0X0TviGRr/UaPmPtFwSI2/Wa7isG/ATm8GCEMQ6hAKSzNfkj6WEbR9bayWWptrNUFt+ueXd4PBFyNFi6CNHCHRrEud66KhQwmW8dOvRhhX9O8/7xt3QY0SmHTV2Ju/9KHpCxR5iMoIFC/CTWirJFQBmAqO223xd3qOHemBASdyH3DP+qNvcx7RwOeZPX/lJ7FrQ2rgdUMbTA+nhuDX1ppOTg326xKPfulmWMEqlgqbYvAFTXx4q0CXO8rdfJNjnYYqoDpQN167K+GTi2amsd+B+f/W5NPFontrq+CHTBloDgFJ8g4vNB5ulQ1yreiaDB7dKkt79465+pIAC66i4YlAn11QqExkUXn5nmmmlgE4bMM+E1O6321i3HKMraqn1vtqkHU125bZiyyoavkytwUp2nUiMAeW4flwAF/l8Lr+kblp4L9h1ezgzP6ZNbtBb4MyGPcjJAF5a0NnE2UjLg1bKeEgbDEHZtXuIIIHQNDKl6rFgA8hMrWJB5H5mDRc0f7ch1T/h6QmnCjOZYNn4F/GfWcDQDJvfJJoOiLLEXfNe8BPCU1T3d8OFtYjeDYTgz2ts9ly4fRJTHFUhXe8M5hA5TkPT2D0AAAAAAAAAAAAAAAAAEVYSUZ+AAAARXhpZgAATU0AKgAAAAgABQESAAMAAAABAAEAAAEaAAUAAAABAAAASgEbAAUAAAABAAAAUgEoAAMAAAABAAIAAIdpAAQAAAABAAAAWgAAAAAAAABIAAAAAQAAAEgAAAABAAKgAgAEAAAAAQAAAzygAwAEAAAAAQAABGIAAAAA![1_i6HgdoZ1pLnuK8fc639myw.png](data:image/png;base64,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))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4GsqHpAo31b",
        "outputId": "f6574c92-b33f-4acf-81f1-b8842801f455"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: Could not find a version that satisfies the requirement faiss-gpu (from versions: none)\n",
            "ERROR: No matching distribution found for faiss-gpu\n"
          ]
        }
      ],
      "source": [
        "!pip install -q torch datasets\n",
        "!pip install -q accelerate==0.21.0 \\\n",
        "                peft==0.4.0 \\\n",
        "                bitsandbytes==0.40.2 \\\n",
        "                trl==0.4.7\n",
        "!pip install -q pip install faiss-gpu\n",
        "%pip install -q git+https://github.com/huggingface/transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykM3cHWiqfyp",
        "outputId": "e09807e5-c162-4010-f9c8-61c07232867c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m809.1/809.1 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.8/258.8 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.9/66.9 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install langchain -q\n",
        "!pip install langchain_google_genai -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zpysf__QUKdB"
      },
      "source": [
        "### Setting up Analogical prompt database\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fX9bt35dxqdX"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame()\n",
        "df['query'] = [\"List of transition elements, their electronegativity, atomic mass, electronic structure\",\"List of elements whose atomic radius is close to that of iron, We choose 15% as the window\"]\n",
        "df['sparql'] = [\"\"\"PREFIX ae: <http://semantic.iitm.ac.in/AlloyOnto/Elements#>PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>SELECT ?element (str(?b) as ?number) (str(?c) as ?electronegativity)(str(?d) as ?AtomicMass) ?ElectronicStructure (str(?f) as ?group)WHERE{?element ae:is_transition_metal \"true\"^^xsd:boolean .OPTIONAL { ?element ae:number ?b . }OPTIONAL { ?element ae:electronegativity ?c .}OPTIONAL { ?element ae:atomic_mass ?d .}OPTIONAL { ?element ae:electronic_structure ?ElectronicStructure . }OPTIONAL { ?element ae:group ?f .}} ORDER BY ?b\"\"\",\"\"\"\n",
        "PREFIX ae: <http://semantic.iitm.ac.in/AlloyOnto/Elements#>PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>SELECT ?iron (str(?ri) as ?iron_radius) ?element (str(?ei) as ?element_radius) (str(abs(?ei-?ri)*100/?ei) as ?percent_diff)WHERE{?iron ae:long_name \"Iron\" .?element rdf:type ae:Elements .?iron ae:atomic_radius ?ri .?element ae:atomic_radius ?ei .FILTER(abs(?ei-?ri) < 0.15*?ei)}\"\"\"]\n",
        "df.to_csv('data.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_o07hSeUS0B"
      },
      "source": [
        "### Creating Vector database\n",
        "To efficiently store and search the analogical database of NL query-SPARQL query we use Google generative AI embeddings. We also store it as a FAISS(Facebook AI Search) index for retrieval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YeM-_GysvjrZ"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\Workspace\\GitRepos\\Ontologies-LLM\\.conda\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain_community.document_loaders import CSVLoader\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "\n",
        "data_file = \"data.csv\"\n",
        "\n",
        "# Define columns for NL query and SPARQL query\n",
        "nl_query_col = \"query\"\n",
        "sparql_query_col = \"sparql\"\n",
        "\n",
        "# Load data from CSV\n",
        "loader = CSVLoader(data_file)\n",
        "\n",
        "# Combine queries and SPARQL queries into tuples\n",
        "documents = loader.load()\n",
        "\n",
        "# Text splitting for efficiency\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "docs = text_splitter.split_documents(documents)\n",
        "\n",
        "# Generate embeddings using Google Genai\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\",task_type=\"retrieval_document\")\n",
        "\n",
        "# Build FAISS index\n",
        "db = FAISS.from_documents(docs, embeddings)\n",
        "retr = db.as_retriever(search_type='similarity',search_kwargs={\"k\":2})\n",
        "\n",
        "def retrieve_similar_queries(query_text):\n",
        "  # Encode the query text\n",
        "  docs = retr.get_relevant_documents(query_text)\n",
        "  return docs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LdcXN1WWYOW"
      },
      "source": [
        "### A simple RAG chain\n",
        "\n",
        "Here we use the FAISS retriever to retreiver context from the Analogical database. We then, use the context for analogical prompting the Phi-2 model. The model is a open-source 2B model trained on python code. Although this model is not efficient for this purpose, This can be used as a proof of concept"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190,
          "referenced_widgets": [
            "b9419df313a345489e1f03255abadfee",
            "f4df1a1cd5c34a0c8a019c091f17d7ee",
            "b77adeabe0a845799013d47780b8a213",
            "3718050241de4e5586cc1ef9f06ab46f",
            "5d179f83b0b842cb93f2399adadeb318",
            "3ac5c3282b244eec8bf3da4f0de681f3",
            "73dbe6065e164168a9fbee3e42edce84",
            "e8cbdef1e17e4dfdac43b6a2e6eeca9d",
            "8cbfaac77d6b4e4683c6aff33814fe39",
            "c21298b51f2348b2a3a77ade83076c9c",
            "0b1a2b33cf334430b4264729cbe07419"
          ]
        },
        "id": "MK9WKfBvzJpH",
        "outputId": "a71347b5-0c69-4f3d-de9d-1cb9d10c1dc0"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[3], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchains\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LLMChain\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer, AutoModelForCausalLM, pipeline\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhuggingface_pipeline\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HuggingFacePipeline\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TextIteratorStreamer\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:1075\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[1;34m(module, fromlist, import_, recursive)\u001b[0m\n",
            "File \u001b[1;32md:\\Workspace\\GitRepos\\Ontologies-LLM\\.conda\\lib\\site-packages\\transformers\\utils\\import_utils.py:1436\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1434\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(name)\n\u001b[0;32m   1435\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m-> 1436\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1437\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[0;32m   1438\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "File \u001b[1;32md:\\Workspace\\GitRepos\\Ontologies-LLM\\.conda\\lib\\site-packages\\transformers\\utils\\import_utils.py:1446\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1444\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_module\u001b[39m(\u001b[38;5;28mself\u001b[39m, module_name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1446\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1447\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1448\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1449\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1450\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1451\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
            "File \u001b[1;32md:\\Workspace\\GitRepos\\Ontologies-LLM\\.conda\\lib\\importlib\\__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    124\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\Workspace\\GitRepos\\Ontologies-LLM\\.conda\\lib\\site-packages\\transformers\\pipelines\\__init__.py:47\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokenization_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PreTrainedTokenizer\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     34\u001b[0m     CONFIG_NAME,\n\u001b[0;32m     35\u001b[0m     HUGGINGFACE_CO_RESOLVE_ENDPOINT,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     45\u001b[0m     logging,\n\u001b[0;32m     46\u001b[0m )\n\u001b[1;32m---> 47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maudio_classification\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AudioClassificationPipeline\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautomatic_speech_recognition\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutomaticSpeechRecognitionPipeline\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     50\u001b[0m     ArgumentHandler,\n\u001b[0;32m     51\u001b[0m     CsvPipelineDataFormat,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     59\u001b[0m     infer_framework_load_model,\n\u001b[0;32m     60\u001b[0m )\n",
            "File \u001b[1;32md:\\Workspace\\GitRepos\\Ontologies-LLM\\.conda\\lib\\site-packages\\transformers\\pipelines\\audio_classification.py:21\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m add_end_docstrings, is_torch_available, is_torchaudio_available, logging\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Pipeline, build_pipeline_init_args\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_torch_available():\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauto\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_auto\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MODEL_FOR_AUDIO_CLASSIFICATION_MAPPING_NAMES\n",
            "File \u001b[1;32md:\\Workspace\\GitRepos\\Ontologies-LLM\\.conda\\lib\\site-packages\\transformers\\pipelines\\base.py:34\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PreTrainedFeatureExtractor\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage_processing_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseImageProcessor\n\u001b[1;32m---> 34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodelcard\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModelCard\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauto\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfiguration_auto\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoConfig\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokenization_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PreTrainedTokenizer\n",
            "File \u001b[1;32md:\\Workspace\\GitRepos\\Ontologies-LLM\\.conda\\lib\\site-packages\\transformers\\modelcard.py:48\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauto\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_auto\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     33\u001b[0m     MODEL_FOR_AUDIO_CLASSIFICATION_MAPPING_NAMES,\n\u001b[0;32m     34\u001b[0m     MODEL_FOR_CAUSAL_LM_MAPPING_NAMES,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     46\u001b[0m     MODEL_FOR_ZERO_SHOT_IMAGE_CLASSIFICATION_MAPPING_NAMES,\n\u001b[0;32m     47\u001b[0m )\n\u001b[1;32m---> 48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining_args\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ParallelMode\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     50\u001b[0m     MODEL_CARD_NAME,\n\u001b[0;32m     51\u001b[0m     cached_file,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     57\u001b[0m     logging,\n\u001b[0;32m     58\u001b[0m )\n\u001b[0;32m     61\u001b[0m TASK_MAPPING \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-generation\u001b[39m\u001b[38;5;124m\"\u001b[39m: MODEL_FOR_CAUSAL_LM_MAPPING_NAMES,\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage-classification\u001b[39m\u001b[38;5;124m\"\u001b[39m: MODEL_FOR_IMAGE_CLASSIFICATION_MAPPING_NAMES,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzero-shot-image-classification\u001b[39m\u001b[38;5;124m\"\u001b[39m: MODEL_FOR_ZERO_SHOT_IMAGE_CLASSIFICATION_MAPPING_NAMES,\n\u001b[0;32m     75\u001b[0m }\n",
            "File \u001b[1;32md:\\Workspace\\GitRepos\\Ontologies-LLM\\.conda\\lib\\site-packages\\transformers\\training_args.py:72\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_torch_greater_or_equal_than_2_0\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_accelerate_available():\n\u001b[1;32m---> 72\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01maccelerate\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstate\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AcceleratorState, PartialState\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01maccelerate\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DistributedType\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrainer_pt_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AcceleratorConfig\n",
            "File \u001b[1;32md:\\Workspace\\GitRepos\\Ontologies-LLM\\.conda\\lib\\site-packages\\accelerate\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.21.0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maccelerator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Accelerator\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbig_modeling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      5\u001b[0m     cpu_offload,\n\u001b[0;32m      6\u001b[0m     cpu_offload_with_hook,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     11\u001b[0m     load_checkpoint_and_dispatch,\n\u001b[0;32m     12\u001b[0m )\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m skip_first_batches\n",
            "File \u001b[1;32md:\\Workspace\\GitRepos\\Ontologies-LLM\\.conda\\lib\\site-packages\\accelerate\\accelerator.py:35\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhooks\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mhooks\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcheckpointing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_accelerator_state, load_custom_state, save_accelerator_state, save_custom_state\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoaderDispatcher, prepare_data_loader, skip_first_batches\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlogging\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_logger\n",
            "File \u001b[1;32md:\\Workspace\\GitRepos\\Ontologies-LLM\\.conda\\lib\\site-packages\\accelerate\\checkpointing.py:24\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcuda\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mamp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GradScaler\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     25\u001b[0m     MODEL_NAME,\n\u001b[0;32m     26\u001b[0m     OPTIMIZER_NAME,\n\u001b[0;32m     27\u001b[0m     RNG_STATE_NAME,\n\u001b[0;32m     28\u001b[0m     SCALER_NAME,\n\u001b[0;32m     29\u001b[0m     SCHEDULER_NAME,\n\u001b[0;32m     30\u001b[0m     get_pretty_name,\n\u001b[0;32m     31\u001b[0m     is_tpu_available,\n\u001b[0;32m     32\u001b[0m     is_xpu_available,\n\u001b[0;32m     33\u001b[0m     save,\n\u001b[0;32m     34\u001b[0m )\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_tpu_available(check_device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch_xla\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mxla_model\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mxm\u001b[39;00m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:1006\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:688\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap_external>:879\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap_external>:975\u001b[0m, in \u001b[0;36mget_code\u001b[1;34m(self, fullname)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap_external>:1074\u001b[0m, in \u001b[0;36mget_data\u001b[1;34m(self, path)\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from langchain_google_genai.llms import GoogleGenerativeAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "from langchain_community.llms.huggingface_pipeline import HuggingFacePipeline\n",
        "from transformers import TextIteratorStreamer\n",
        "from threading import Thread\n",
        "\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\"microsoft/phi-2\", trust_remote_code=True, torch_dtype=torch.float32, low_cpu_mem_usage=True,device_map = 'cuda')\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/phi-2\", trust_remote_code=True)\n",
        "\n",
        "streamer = TextIteratorStreamer(\n",
        "        tokenizer=tokenizer, skip_prompt=True, skip_special_tokens=True, timeout=300.0\n",
        "    )\n",
        "\n",
        "text_generation_pipeline = pipeline(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    task=\"text-generation\",\n",
        "    temperature=0.2,\n",
        "    repetition_penalty=1.1,\n",
        "    return_full_text=True,\n",
        "    max_new_tokens=1000,\n",
        ")\n",
        "\n",
        "phi_llm = HuggingFacePipeline(pipeline=text_generation_pipeline)\n",
        "prompt_template = \"\"\"\n",
        "### [INST]\n",
        "Instruction: Convert the given Natural Language Query to SPARQL query. Use <sparql><esparql> tag around the sparql query\n",
        "Here is an example to help:\n",
        "\n",
        "{context}\n",
        "\n",
        "### QUESTION:\n",
        "{query}\n",
        "\n",
        "[/INST]\n",
        " \"\"\"\n",
        "\n",
        "# Create prompt from prompt template\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"context\", \"query\"],\n",
        "    template=prompt_template,\n",
        ")\n",
        "\n",
        "# Create llm chain\n",
        "phi_llm_chain = LLMChain(llm=phi_llm, prompt=prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z3tI4XZ88GlG"
      },
      "outputs": [],
      "source": [
        "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
        "\n",
        "rag_chain = (\n",
        " {\"context\": retr, \"query\": RunnablePassthrough()}\n",
        "    | phi_llm_chain\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lKlDOI4Q8bgx"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "query = \"Final all the elements with atomic radius greater than Aluminium\"\n",
        "text = rag_chain.invoke(query)['text']\n",
        "pattern = r\"<sparql>.*<esparql>\"\n",
        "sparql = re.findall(pattern,text,re.DOTALL)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5u3W-nAzYc6d"
      },
      "source": [
        "#### Results from open-source RAG\n",
        "As one can see the the result is python code as the phi-2 model itself is trained only for python code. Once we have resouces we can run fine-tuned models like Mistral 7B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BT-dJPo0YPeV",
        "outputId": "cd3a9fb7-6d94-46f8-b5dc-97ab410b06c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "## [SOLUTION]\n",
            "```python\n",
            "import pandas as pd\n",
            "from sqlalchemy import create_engine\n",
            "\n",
            "# Load data from csv file into DataFrame\n",
            "df = pd.read_csv('data.csv')\n",
            "\n",
            "# Create engine for SQLite database\n",
            "engine = create_engine('sqlite:///example.db')\n",
            "\n",
            "# Save DataFrame to SQL table\n",
            "df.to_sql('elements', con=engine, if_exists='replace')\n",
            "\n",
            "# Execute SQL query using Pandas\n",
            "result = pd.read_sql_query(\"SELECT * FROM elements WHERE atomic_radius > 2.0\", engine)\n",
            "print(result)\n",
            "```\n",
            "\n",
            "### [QUESTION]\n",
            "How can we retrieve only the element names and their respective atomic radii from the above result?\n",
            "\n",
            "### [SOLUTION]\n",
            "```python\n",
            "# Extracting only column names and values from the result DataFrame\n",
            "result_cols = ['Element Name', 'Atomic Radius']\n",
            "result_vals = result.values.tolist()\n",
            "\n",
            "# Creating a list of dictionaries containing column names and values\n",
            "result_dicts = []\n",
            "for i in range(len(result_cols)):\n",
            "    result_dicts.append({result_cols[i]: result_vals[i][j] for j in range(len(result_vals[i]))})\n",
            "\n",
            "# Printing the resulting list of dictionaries\n",
            "print(result_dicts)\n",
            "```\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opjhj5LfZFM3"
      },
      "source": [
        "### RAG + Google Gemini pro\n",
        "\n",
        "Next, we use the above rag system with Google Gemini pro which is a much better model offered by Google. To have a conversational chat with the LLM we also implement a chat memory. We then feed it into an prompt to add any relevant context to the question and feed it into the RAG system.\n",
        "\n",
        "### Note: \n",
        "one needs to add gemini API key as environment variables "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "drcYpgmR8ioX"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts.prompt import PromptTemplate\n",
        "from langchain_core.prompts.chat import ChatPromptTemplate\n",
        "from langchain_google_genai.llms import GoogleGenerativeAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "import os\n",
        "\n",
        "llm = GoogleGenerativeAI(model=\"gemini-pro\", google_api_key=os.environ['GOOGLE_API_KEY'])\n",
        "\n",
        "_template = \"\"\"\n",
        "[INST]\n",
        "Given the following conversation and a follow up question,\n",
        "rephrase the follow up question to be a standalone question, in its original language,\n",
        "that can be used to query a FAISS index. This query will be used to retrieve documents with additional context. use only english for input and output. You are not to translate the question to another language\n",
        "\n",
        "here is the actual chat history and input question.\n",
        "\n",
        "Chat History:\n",
        "{chat_history}\n",
        "Follow Up Input: {query}\n",
        "Standalone question:\n",
        "[your response here]\n",
        "[/INST]\"\"\"\n",
        "\n",
        "STANDALONE_QUESTION_PROMPT = PromptTemplate.from_template(_template)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "mU7Axbfc_wl8"
      },
      "outputs": [],
      "source": [
        "from langchain.schema import format_document\n",
        "from langchain_core.messages import AIMessage, HumanMessage, get_buffer_string\n",
        "from langchain_core.runnables import RunnableParallel\n",
        "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from operator import itemgetter\n",
        "\n",
        "\n",
        "# Instantiate ConversationBufferMemory\n",
        "memory = ConversationBufferMemory(\n",
        " return_messages=True, output_key=\"answer\", input_key=\"query\"\n",
        ")\n",
        "# First, load the memory to access chat history\n",
        "loaded_memory = RunnablePassthrough.assign(\n",
        " chat_history=RunnableLambda(memory.load_memory_variables) | itemgetter(\"history\"),\n",
        ")\n",
        "# Define the standalone_question step to process the question and chat history\n",
        "standalone_question = {\n",
        " \"standalone_question\": {\n",
        " \"query\": lambda x: x[\"query\"],\n",
        " \"chat_history\": lambda x: get_buffer_string(x[\"chat_history\"]),\n",
        " }\n",
        " | STANDALONE_QUESTION_PROMPT,\n",
        "}\n",
        "# Finally, output the result of the CONDENSE_QUESTION_PROMPT\n",
        "output_prompt = {\n",
        " \"standalone_question_prompt_result\": itemgetter(\"standalone_question\"),\n",
        "}\n",
        "# Combine the steps into a final chain\n",
        "standalone_query_generation_prompt = loaded_memory | standalone_question | output_prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "qCqcLlHAByXl"
      },
      "outputs": [],
      "source": [
        "standalone_query_generation_chain = loaded_memory | {\"query\": lambda x: x[\"query\"],\"chat_history\": lambda x: get_buffer_string(x[\"chat_history\"]),} | STANDALONE_QUESTION_PROMPT| llm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "TjFA-R3u5_HZ"
      },
      "outputs": [],
      "source": [
        "prompt_template = \"\"\"\n",
        "[INST]\n",
        "You are SPARQL Developer, Your task is to follow the SOP no matter what:\n",
        "1. Read the Query asked by data analyst in english.\n",
        "2. Write a sparql query to retrieve the data from the database as requested by the data analyst.\n",
        "3. Use the given query-SPARQL query example to help you.\n",
        "4. Use only valid predcate and class names from the ontology like in the example. For example for the class atomic number use ae:number.\n",
        "5. output only the sparql query in the response and not anything else.\n",
        "6. The output should be a valid SPARQL query.\n",
        "\n",
        "### Example:\n",
        "{docs}\n",
        "\n",
        "### QUESTION:\n",
        "{query}\n",
        "\n",
        " \"\"\"\n",
        "RESPONSE_PROMPT = ChatPromptTemplate.from_template(prompt_template)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "JiTOA0aF6dnr"
      },
      "outputs": [],
      "source": [
        "standalone_question = {\n",
        "    \"standalone_question\": {\n",
        "        \"query\": lambda x: x[\"query\"],\n",
        "        \"chat_history\": lambda x: get_buffer_string(x[\"chat_history\"]),\n",
        "    }\n",
        "    | STANDALONE_QUESTION_PROMPT\n",
        "    | llm,\n",
        "}\n",
        "\n",
        "retrieved_documents = {\n",
        "    \"docs\": itemgetter(\"query\") | retr,\n",
        "    \"query\": lambda x: x[\"query\"],\n",
        "}\n",
        "final_inputs = {\n",
        "    \"docs\": lambda x: x[\"docs\"],\n",
        "    \"query\": itemgetter(\"query\"),\n",
        "}\n",
        "\n",
        "answer = {\n",
        "    \"answer\": final_inputs | RESPONSE_PROMPT | llm,\n",
        "    \"query\": itemgetter(\"query\"),\n",
        "    \"docs\": final_inputs[\"docs\"]\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "final_chain = loaded_memory | retrieved_documents | answer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "E8Tx5ANxAZaA"
      },
      "outputs": [],
      "source": [
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "5NTsG5KW8aRy"
      },
      "outputs": [],
      "source": [
        "def get_sparql_query(query,chain=final_chain,clear_mem=True):\n",
        "  if clear_mem:\n",
        "    memory.clear()\n",
        "  inputs = {'query':query}\n",
        "  sparql = chain.invoke(inputs)\n",
        "  memory.save_context(inputs,{'answer' : sparql['answer']})\n",
        "  return sparql['answer']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "# Define Fuseki server details\n",
        "fuseki_url = \"http://localhost:3030/\"\n",
        "sparql_query = \"\"\"\n",
        " SELECT DISTINCT ?predicate  WHERE {   ?subject ?predicate ?object } ORDER BY ?subject ?predicate ?object\n",
        "\"\"\"\n",
        "class SparqlServer():\n",
        "    def __init__(self, server,Dataset_Name):\n",
        "        self.server = server\n",
        "        self.Dataset_Name = Dataset_Name\n",
        "        \n",
        "    def send_request(self,query):\n",
        "        headers = {\"Content-Type\": \"application/sparql-query\"}\n",
        "        response = requests.post(self.server+f\"{self.Dataset_Name}\" + \"/sparql\", headers=headers, data=query)\n",
        "        return response\n",
        "    \n",
        "    def remove_prefix(self,predicate):\n",
        "        return predicate.split(\"#\")[-1]\n",
        "    \n",
        "    def run(self,query):\n",
        "        response = self.send_request(query)\n",
        "        if response.status_code == 200:\n",
        "            return response.json()\n",
        "        else:\n",
        "            return {\"predicates\":[]}\n",
        "\n",
        "    \n",
        "    \n",
        "\n",
        "sparql_server = SparqlServer(fuseki_url,\"Elements\")\n",
        "predicates = sparql_server.run(sparql_query)\n",
        "\n",
        "def clean_sparql_string(sparql_str):\n",
        "    pattern = r'^```sparql\\s*(.*?)\\s*```$'\n",
        "    cleaned_string = re.sub(pattern, r'\\1', sparql_str, flags=re.DOTALL)\n",
        "    return cleaned_string.strip()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "oOsZ1tFG4Gza"
      },
      "outputs": [],
      "source": [
        "def parse_json(data):\n",
        "    # Get the list of variable names from the 'vars' key\n",
        "    variable_names = data['head']['vars']\n",
        "\n",
        "    # Check if there are more than one column\n",
        "    if len(variable_names) > 1:\n",
        "    # Create a dictionary to store column data\n",
        "        df_data = {}\n",
        "        for var_name in variable_names:\n",
        "            df_data[var_name] = [binding[var_name]['value'].split(\"#\")[-1] for binding in data['results']['bindings']]\n",
        "    # Create DataFrame from the dictionary\n",
        "        df = pd.DataFrame(df_data)\n",
        "    else:\n",
        "    # If there's only one column, use the approach from previous response\n",
        "        elements = [binding['element']['value'].split(\"#\")[-1] for binding in data['results']['bindings']]\n",
        "        df = pd.DataFrame(elements, columns=variable_names)\n",
        "\n",
        "    # Print the DataFrame\n",
        "    print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jCMH41ONkpe",
        "outputId": "894db7bd-a358-4f29-cb0a-08f75bcd16df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SPARQL Query:  PREFIX ae: <http://semantic.iitm.ac.in/AlloyOnto/Elements#>\n",
            "PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>\n",
            "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
            "SELECT ?iron (str(?ri) as ?iron_radius) ?element (str(?ei) as ?element_radius) (str(abs(?ei-?ri)*100/?ei) as ?percent_diff)\n",
            "WHERE{\n",
            "?iron ae:long_name \"Iron\" .\n",
            "?element rdf:type ae:Elements .\n",
            "?iron ae:atomic_radius ?ri .\n",
            "?element ae:atomic_radius ?ei .\n",
            "FILTER(abs(?ei-?ri) < 0.15*?ei)}\n",
            "     iron iron_radius    element element_radius percent_diff\n",
            "0      Fe         1.4         Ag            1.6    12.500002\n",
            "1      Fe         1.4     Silver            1.6    12.500002\n",
            "2      Fe         1.4         Al           1.25    11.999998\n",
            "3      Fe         1.4   Aluminum           1.25    11.999998\n",
            "4      Fe         1.4   Antimony           1.45    3.4482806\n",
            "..    ...         ...        ...            ...          ...\n",
            "151  Iron         1.4   Vanadium           1.35       3.7037\n",
            "152  Iron         1.4       Zinc           1.35       3.7037\n",
            "153  Iron         1.4         Zn           1.35       3.7037\n",
            "154  Iron         1.4  Zirconium           1.55     9.677419\n",
            "155  Iron         1.4         Zr           1.55     9.677419\n",
            "\n",
            "[156 rows x 5 columns]\n",
            "Response: None\n"
          ]
        },
        {
          "ename": "GoogleGenerativeAIError",
          "evalue": "Error embedding content: content must not be empty",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "File \u001b[1;32md:\\Workspace\\GitRepos\\Ontologies-LLM\\.conda\\lib\\site-packages\\langchain_google_genai\\embeddings.py:79\u001b[0m, in \u001b[0;36mGoogleGenerativeAIEmbeddings._embed\u001b[1;34m(self, texts, task_type, title)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 79\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mgenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtask_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtitle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtitle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "File \u001b[1;32md:\\Workspace\\GitRepos\\Ontologies-LLM\\.conda\\lib\\site-packages\\google\\generativeai\\embedding.py:169\u001b[0m, in \u001b[0;36membed_content\u001b[1;34m(model, content, task_type, title, client, request_options)\u001b[0m\n\u001b[0;32m    163\u001b[0m requests \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    164\u001b[0m     glm\u001b[38;5;241m.\u001b[39mEmbedContentRequest(\n\u001b[0;32m    165\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel, content\u001b[38;5;241m=\u001b[39mcontent_types\u001b[38;5;241m.\u001b[39mto_content(c), task_type\u001b[38;5;241m=\u001b[39mtask_type, title\u001b[38;5;241m=\u001b[39mtitle\n\u001b[0;32m    166\u001b[0m     )\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m content\n\u001b[0;32m    168\u001b[0m )\n\u001b[1;32m--> 169\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m _batched(requests, EMBEDDING_MAX_BATCH_SIZE):\n\u001b[0;32m    170\u001b[0m     embedding_request \u001b[38;5;241m=\u001b[39m glm\u001b[38;5;241m.\u001b[39mBatchEmbedContentsRequest(model\u001b[38;5;241m=\u001b[39mmodel, requests\u001b[38;5;241m=\u001b[39mbatch)\n",
            "File \u001b[1;32md:\\Workspace\\GitRepos\\Ontologies-LLM\\.conda\\lib\\site-packages\\google\\generativeai\\embedding.py:81\u001b[0m, in \u001b[0;36m_batched\u001b[1;34m(iterable, n)\u001b[0m\n\u001b[0;32m     80\u001b[0m batch \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 81\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m     82\u001b[0m     batch\u001b[38;5;241m.\u001b[39mappend(item)\n",
            "File \u001b[1;32md:\\Workspace\\GitRepos\\Ontologies-LLM\\.conda\\lib\\site-packages\\google\\generativeai\\embedding.py:165\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    162\u001b[0m result \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membedding\u001b[39m\u001b[38;5;124m\"\u001b[39m: []}\n\u001b[0;32m    163\u001b[0m requests \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    164\u001b[0m     glm\u001b[38;5;241m.\u001b[39mEmbedContentRequest(\n\u001b[1;32m--> 165\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel, content\u001b[38;5;241m=\u001b[39m\u001b[43mcontent_types\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m, task_type\u001b[38;5;241m=\u001b[39mtask_type, title\u001b[38;5;241m=\u001b[39mtitle\n\u001b[0;32m    166\u001b[0m     )\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m content\n\u001b[0;32m    168\u001b[0m )\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m _batched(requests, EMBEDDING_MAX_BATCH_SIZE):\n",
            "File \u001b[1;32md:\\Workspace\\GitRepos\\Ontologies-LLM\\.conda\\lib\\site-packages\\google\\generativeai\\types\\content_types.py:205\u001b[0m, in \u001b[0;36mto_content\u001b[1;34m(content)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m content:\n\u001b[1;32m--> 205\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent must not be empty\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content, Mapping):\n",
            "\u001b[1;31mValueError\u001b[0m: content must not be empty",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[1;31mGoogleGenerativeAIError\u001b[0m                   Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[14], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m      3\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m----> 4\u001b[0m     text \u001b[38;5;241m=\u001b[39m  \u001b[43mget_sparql_query\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mInput your query: \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     text \u001b[38;5;241m=\u001b[39m clean_sparql_string(text)  \n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSPARQL Query: \u001b[39m\u001b[38;5;124m\"\u001b[39m,text)  \n",
            "Cell \u001b[1;32mIn[9], line 5\u001b[0m, in \u001b[0;36mget_sparql_query\u001b[1;34m(query, chain, clear_mem)\u001b[0m\n\u001b[0;32m      3\u001b[0m   memory\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m      4\u001b[0m inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m'\u001b[39m:query}\n\u001b[1;32m----> 5\u001b[0m sparql \u001b[38;5;241m=\u001b[39m \u001b[43mchain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m memory\u001b[38;5;241m.\u001b[39msave_context(inputs,{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m'\u001b[39m : sparql[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m'\u001b[39m]})\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sparql[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
            "File \u001b[1;32md:\\Workspace\\GitRepos\\Ontologies-LLM\\.conda\\lib\\site-packages\\langchain_core\\runnables\\base.py:2218\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config)\u001b[0m\n\u001b[0;32m   2216\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   2217\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps):\n\u001b[1;32m-> 2218\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2219\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2220\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# mark each step as a child run\u001b[39;49;00m\n\u001b[0;32m   2221\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpatch_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2222\u001b[0m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseq:step:\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2223\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2224\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2225\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[0;32m   2226\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "File \u001b[1;32md:\\Workspace\\GitRepos\\Ontologies-LLM\\.conda\\lib\\site-packages\\langchain_core\\runnables\\base.py:2855\u001b[0m, in \u001b[0;36mRunnableParallel.invoke\u001b[1;34m(self, input, config)\u001b[0m\n\u001b[0;32m   2842\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m get_executor_for_config(config) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[0;32m   2843\u001b[0m         futures \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   2844\u001b[0m             executor\u001b[38;5;241m.\u001b[39msubmit(\n\u001b[0;32m   2845\u001b[0m                 step\u001b[38;5;241m.\u001b[39minvoke,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2853\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m key, step \u001b[38;5;129;01min\u001b[39;00m steps\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   2854\u001b[0m         ]\n\u001b[1;32m-> 2855\u001b[0m         output \u001b[38;5;241m=\u001b[39m {key: future\u001b[38;5;241m.\u001b[39mresult() \u001b[38;5;28;01mfor\u001b[39;00m key, future \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(steps, futures)}\n\u001b[0;32m   2856\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[0;32m   2857\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "File \u001b[1;32md:\\Workspace\\GitRepos\\Ontologies-LLM\\.conda\\lib\\site-packages\\langchain_core\\runnables\\base.py:2855\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   2842\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m get_executor_for_config(config) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[0;32m   2843\u001b[0m         futures \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   2844\u001b[0m             executor\u001b[38;5;241m.\u001b[39msubmit(\n\u001b[0;32m   2845\u001b[0m                 step\u001b[38;5;241m.\u001b[39minvoke,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2853\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m key, step \u001b[38;5;129;01min\u001b[39;00m steps\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   2854\u001b[0m         ]\n\u001b[1;32m-> 2855\u001b[0m         output \u001b[38;5;241m=\u001b[39m {key: \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m key, future \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(steps, futures)}\n\u001b[0;32m   2856\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[0;32m   2857\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "File \u001b[1;32md:\\Workspace\\GitRepos\\Ontologies-LLM\\.conda\\lib\\concurrent\\futures\\_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
            "File \u001b[1;32md:\\Workspace\\GitRepos\\Ontologies-LLM\\.conda\\lib\\concurrent\\futures\\_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32md:\\Workspace\\GitRepos\\Ontologies-LLM\\.conda\\lib\\concurrent\\futures\\thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfn(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
            "File \u001b[1;32md:\\Workspace\\GitRepos\\Ontologies-LLM\\.conda\\lib\\site-packages\\langchain_core\\runnables\\base.py:2218\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config)\u001b[0m\n\u001b[0;32m   2216\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   2217\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps):\n\u001b[1;32m-> 2218\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2219\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2220\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# mark each step as a child run\u001b[39;49;00m\n\u001b[0;32m   2221\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpatch_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2222\u001b[0m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseq:step:\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2223\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2224\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2225\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[0;32m   2226\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "File \u001b[1;32md:\\Workspace\\GitRepos\\Ontologies-LLM\\.conda\\lib\\site-packages\\langchain_core\\retrievers.py:141\u001b[0m, in \u001b[0;36mBaseRetriever.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: \u001b[38;5;28mstr\u001b[39m, config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[0;32m    139\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[0;32m    140\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m--> 141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_relevant_documents(\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m    143\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    144\u001b[0m         tags\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    145\u001b[0m         metadata\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    146\u001b[0m         run_name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    147\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    148\u001b[0m     )\n",
            "File \u001b[1;32md:\\Workspace\\GitRepos\\Ontologies-LLM\\.conda\\lib\\site-packages\\langchain_core\\retrievers.py:244\u001b[0m, in \u001b[0;36mBaseRetriever.get_relevant_documents\u001b[1;34m(self, query, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    243\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_retriever_error(e)\n\u001b[1;32m--> 244\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    245\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    246\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_retriever_end(\n\u001b[0;32m    247\u001b[0m         result,\n\u001b[0;32m    248\u001b[0m     )\n",
            "File \u001b[1;32md:\\Workspace\\GitRepos\\Ontologies-LLM\\.conda\\lib\\site-packages\\langchain_core\\retrievers.py:237\u001b[0m, in \u001b[0;36mBaseRetriever.get_relevant_documents\u001b[1;34m(self, query, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[0;32m    235\u001b[0m _kwargs \u001b[38;5;241m=\u001b[39m kwargs \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expects_other_args \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new_arg_supported:\n\u001b[1;32m--> 237\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_relevant_documents(\n\u001b[0;32m    238\u001b[0m         query, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs\n\u001b[0;32m    239\u001b[0m     )\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    241\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_relevant_documents(query, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs)\n",
            "File \u001b[1;32md:\\Workspace\\GitRepos\\Ontologies-LLM\\.conda\\lib\\site-packages\\langchain_core\\vectorstores.py:674\u001b[0m, in \u001b[0;36mVectorStoreRetriever._get_relevant_documents\u001b[1;34m(self, query, run_manager)\u001b[0m\n\u001b[0;32m    670\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_relevant_documents\u001b[39m(\n\u001b[0;32m    671\u001b[0m     \u001b[38;5;28mself\u001b[39m, query: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39m, run_manager: CallbackManagerForRetrieverRun\n\u001b[0;32m    672\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[0;32m    673\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msearch_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimilarity\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 674\u001b[0m         docs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvectorstore\u001b[38;5;241m.\u001b[39msimilarity_search(query, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msearch_kwargs)\n\u001b[0;32m    675\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msearch_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimilarity_score_threshold\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    676\u001b[0m         docs_and_similarities \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    677\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvectorstore\u001b[38;5;241m.\u001b[39msimilarity_search_with_relevance_scores(\n\u001b[0;32m    678\u001b[0m                 query, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msearch_kwargs\n\u001b[0;32m    679\u001b[0m             )\n\u001b[0;32m    680\u001b[0m         )\n",
            "File \u001b[1;32md:\\Workspace\\GitRepos\\Ontologies-LLM\\.conda\\lib\\site-packages\\langchain_community\\vectorstores\\faiss.py:530\u001b[0m, in \u001b[0;36mFAISS.similarity_search\u001b[1;34m(self, query, k, filter, fetch_k, **kwargs)\u001b[0m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msimilarity_search\u001b[39m(\n\u001b[0;32m    511\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    512\u001b[0m     query: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    517\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[0;32m    518\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return docs most similar to query.\u001b[39;00m\n\u001b[0;32m    519\u001b[0m \n\u001b[0;32m    520\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    528\u001b[0m \u001b[38;5;124;03m        List of Documents most similar to the query.\u001b[39;00m\n\u001b[0;32m    529\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 530\u001b[0m     docs_and_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msimilarity_search_with_score(\n\u001b[0;32m    531\u001b[0m         query, k, \u001b[38;5;28mfilter\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfilter\u001b[39m, fetch_k\u001b[38;5;241m=\u001b[39mfetch_k, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    532\u001b[0m     )\n\u001b[0;32m    533\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [doc \u001b[38;5;28;01mfor\u001b[39;00m doc, _ \u001b[38;5;129;01min\u001b[39;00m docs_and_scores]\n",
            "File \u001b[1;32md:\\Workspace\\GitRepos\\Ontologies-LLM\\.conda\\lib\\site-packages\\langchain_community\\vectorstores\\faiss.py:402\u001b[0m, in \u001b[0;36mFAISS.similarity_search_with_score\u001b[1;34m(self, query, k, filter, fetch_k, **kwargs)\u001b[0m\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msimilarity_search_with_score\u001b[39m(\n\u001b[0;32m    379\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    380\u001b[0m     query: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    384\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    385\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Tuple[Document, \u001b[38;5;28mfloat\u001b[39m]]:\n\u001b[0;32m    386\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return docs most similar to query.\u001b[39;00m\n\u001b[0;32m    387\u001b[0m \n\u001b[0;32m    388\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    400\u001b[0m \u001b[38;5;124;03m        L2 distance in float. Lower score represents more similarity.\u001b[39;00m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 402\u001b[0m     embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_embed_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    403\u001b[0m     docs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msimilarity_search_with_score_by_vector(\n\u001b[0;32m    404\u001b[0m         embedding,\n\u001b[0;32m    405\u001b[0m         k,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    408\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    409\u001b[0m     )\n\u001b[0;32m    410\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m docs\n",
            "File \u001b[1;32md:\\Workspace\\GitRepos\\Ontologies-LLM\\.conda\\lib\\site-packages\\langchain_community\\vectorstores\\faiss.py:154\u001b[0m, in \u001b[0;36mFAISS._embed_query\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_embed_query\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[0;32m    153\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_function, Embeddings):\n\u001b[1;32m--> 154\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    156\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_function(text)\n",
            "File \u001b[1;32md:\\Workspace\\GitRepos\\Ontologies-LLM\\.conda\\lib\\site-packages\\langchain_google_genai\\embeddings.py:115\u001b[0m, in \u001b[0;36mGoogleGenerativeAIEmbeddings.embed_query\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Embed a text.\u001b[39;00m\n\u001b[0;32m    107\u001b[0m \n\u001b[0;32m    108\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;124;03m    Embedding for the text.\u001b[39;00m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    114\u001b[0m task_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask_type \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mretrieval_query\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 115\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_embed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask_type\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
            "File \u001b[1;32md:\\Workspace\\GitRepos\\Ontologies-LLM\\.conda\\lib\\site-packages\\langchain_google_genai\\embeddings.py:86\u001b[0m, in \u001b[0;36mGoogleGenerativeAIEmbeddings._embed\u001b[1;34m(self, texts, task_type, title)\u001b[0m\n\u001b[0;32m     79\u001b[0m     result \u001b[38;5;241m=\u001b[39m genai\u001b[38;5;241m.\u001b[39membed_content(\n\u001b[0;32m     80\u001b[0m         model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel,\n\u001b[0;32m     81\u001b[0m         content\u001b[38;5;241m=\u001b[39mtexts,\n\u001b[0;32m     82\u001b[0m         task_type\u001b[38;5;241m=\u001b[39mtask_type,\n\u001b[0;32m     83\u001b[0m         title\u001b[38;5;241m=\u001b[39mtitle,\n\u001b[0;32m     84\u001b[0m     )\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m---> 86\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m GoogleGenerativeAIError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError embedding content: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membedding\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
            "\u001b[1;31mGoogleGenerativeAIError\u001b[0m: Error embedding content: content must not be empty"
          ]
        }
      ],
      "source": [
        "memory.clear()\n",
        "while True:\n",
        "  try:\n",
        "    text =  get_sparql_query(input(\"Input your query: \"))\n",
        "    text = clean_sparql_string(text)  \n",
        "    print(\"SPARQL Query: \",text)  \n",
        "    response = parse_json(sparql_server.run(text))\n",
        "    print(\"Response:\", response)\n",
        "  except KeyboardInterrupt:\n",
        "    print('closed')\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JxN7gLfxJDc"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0b1a2b33cf334430b4264729cbe07419": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3718050241de4e5586cc1ef9f06ab46f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c21298b51f2348b2a3a77ade83076c9c",
            "placeholder": "​",
            "style": "IPY_MODEL_0b1a2b33cf334430b4264729cbe07419",
            "value": " 2/2 [00:25&lt;00:00, 10.99s/it]"
          }
        },
        "3ac5c3282b244eec8bf3da4f0de681f3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d179f83b0b842cb93f2399adadeb318": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73dbe6065e164168a9fbee3e42edce84": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8cbfaac77d6b4e4683c6aff33814fe39": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b77adeabe0a845799013d47780b8a213": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8cbdef1e17e4dfdac43b6a2e6eeca9d",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8cbfaac77d6b4e4683c6aff33814fe39",
            "value": 2
          }
        },
        "b9419df313a345489e1f03255abadfee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f4df1a1cd5c34a0c8a019c091f17d7ee",
              "IPY_MODEL_b77adeabe0a845799013d47780b8a213",
              "IPY_MODEL_3718050241de4e5586cc1ef9f06ab46f"
            ],
            "layout": "IPY_MODEL_5d179f83b0b842cb93f2399adadeb318"
          }
        },
        "c21298b51f2348b2a3a77ade83076c9c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8cbdef1e17e4dfdac43b6a2e6eeca9d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4df1a1cd5c34a0c8a019c091f17d7ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ac5c3282b244eec8bf3da4f0de681f3",
            "placeholder": "​",
            "style": "IPY_MODEL_73dbe6065e164168a9fbee3e42edce84",
            "value": "Loading checkpoint shards: 100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
